{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da82003-0d84-4548-add1-242747534f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../src\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20845c22-fe21-4c71-b49b-48d79b2082ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ddpm_unet_cattn import SPVUnet\n",
    "import torch\n",
    "import lightning as L\n",
    "from models.g_spvd import GSPVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5649e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "# steps_to_run = [1000, 500, 250, 125, 63, 32, 16, 8, 4, 2]\n",
    "steps_to_run = [1000]\n",
    "on_all = True\n",
    "distilled = False\n",
    "scheduler = 'ddpm'\n",
    "\n",
    "categories = ['chair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249073ab-7415-4203-ade8-42a077ded01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataloaders.shapenet.shapenet_loader import ShapeNet\n",
    "\n",
    "path = \"../data/ShapeNet\"\n",
    "\n",
    "test_dataset = ShapeNet(path, \"test\", 2048, categories, load_renders=True, total=800 if on_all else 5)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35c796-1d0f-44df-876c-22d74ee96ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hyperparams import load_hyperparams\n",
    "\n",
    "hparams_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/hparams.yaml'\n",
    "\n",
    "hparams = load_hyperparams(hparams_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab32803-eef3-4c2c-82e1-52fd6af63063",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'voxel_size' : hparams['voxel_size'],\n",
    "    'nfs' : hparams['nfs'], \n",
    "    'attn_chans' : hparams['attn_chans'], \n",
    "    'attn_start' : hparams['attn_start'], \n",
    "    'cross_attn_chans' : hparams['cross_attn_chans'], \n",
    "    'cross_attn_start' : hparams['cross_attn_start'], \n",
    "    'cross_attn_cond_dim' : hparams['cross_attn_cond_dim'],\n",
    "}\n",
    "\n",
    "model = SPVUnet(**model_args)\n",
    "model = GSPVD(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946f0a2-d343-4d56-847f-c55de5273595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a8036-ef5c-4200-bb05-74ea77a1e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_schedulers.ddpm_scheduler import DDPMSparseScheduler\n",
    "from my_schedulers.ddim_scheduler import DDIMSparseScheduler\n",
    "from utils.helper_functions import process_ckpt\n",
    "from schedulers.factory import create_sparse_scheduler\n",
    "\n",
    "\n",
    "def get_sched(steps, dist, scheduler):\n",
    "    \n",
    "    return create_sparse_scheduler(\n",
    "        scheduler_strategy=scheduler.upper(),\n",
    "        beta_min=hparams['beta_min'], \n",
    "        beta_max=hparams['beta_max'], \n",
    "        n_steps=steps, \n",
    "        scheduling_method='linear' if hparams['mode'] == 'linear' else 'warmup',\n",
    "    )\n",
    "\n",
    "def get_ckpt(steps, dist, scheduler):\n",
    "    if dist:\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/new/{steps}-steps.ckpt'\n",
    "    elif scheduler == 'ddim':\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "    else:\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "    ckpt = process_ckpt(ckpt)\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30779293-ab3f-40fe-a825-70e470751932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from metrics.chamfer_dist import ChamferDistanceL2\n",
    "from metrics.PyTorchEMD.emd import earth_mover_distance as EMD\n",
    "from utils.helper_functions import normalize_to_unit_sphere, standardize, normalize_to_unit_cube\n",
    "\n",
    "def run_test(steps):\n",
    "    CD = ChamferDistanceL2()\n",
    "    \n",
    "    sched = get_sched(steps, distilled, scheduler)\n",
    "\n",
    "    ckpt = get_ckpt(steps, distilled, scheduler)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "    cd_mean = 0\n",
    "    emd_mean = 0\n",
    "    cd_mean_norm_sphere = 0\n",
    "    emd_mean_norm_sphere = 0\n",
    "    n = 0\n",
    "    \n",
    "    mean = torch.tensor(test_dataset.mean).cuda()\n",
    "    std = torch.tensor(test_dataset.std).cuda()\n",
    "    \n",
    "    for datapoint in tqdm(test_loader):\n",
    "        ref_pc = datapoint['pc'].cuda()\n",
    "        features = datapoint['render-features'].cuda()\n",
    "\n",
    "        B, N, C = ref_pc.shape\n",
    "        gen_pc = sched.sample(model=model, bs=B, n_points=N, nf=C, cond_emb=features, mode='guided', guidance_scale=0.7).cuda()\n",
    "        \n",
    "        # print(ref_pc.device, gen_pc.device)\n",
    "        ref_pc = ref_pc * std + mean\n",
    "        gen_pc = gen_pc * std + mean\n",
    "        \n",
    "        # ref_pc: (B, N, F)\n",
    "        ref_pc_zero = ref_pc - ref_pc.mean(dim=1, keepdim=True)\n",
    "        gen_pc_zero = gen_pc - gen_pc.mean(dim=1, keepdim=True)\n",
    "\n",
    "        # ref_pc_zero.mean: (B, 1, F)\n",
    "        # ref_pc_zero.std: (B, 1, 1) \n",
    "        ref_pc_zero = ref_pc_zero / ref_pc_zero.std(dim=(1, 2), keepdim=True)\n",
    "        gen_pc_zero = gen_pc_zero / gen_pc_zero.std(dim=(1, 2), keepdim=True)\n",
    "        \n",
    "\n",
    "        cd_mean += CD(ref_pc_zero, gen_pc_zero).item() * B\n",
    "        # emd_mean += EMD(ref_pc, gen_pc, transpose=False).sum().item()\n",
    "        \n",
    "        ref_pc_norm = normalize_to_unit_sphere(ref_pc)\n",
    "        gen_pc_norm = normalize_to_unit_sphere(gen_pc)\n",
    "\n",
    "        cd_mean_norm_sphere += CD(ref_pc_norm, gen_pc_norm).item() * B\n",
    "        # emd_mean_norm_sphere += EMD(ref_pc_norm, gen_pc_norm, transpose=False).sum().item()\n",
    "        \n",
    "        n += B\n",
    "        \n",
    "    cd_mean /= n\n",
    "    emd_mean /= n\n",
    "    \n",
    "    cd_mean_norm_sphere /= n\n",
    "    emd_mean_norm_sphere /= n\n",
    "    \n",
    "    print(f\"Steps: {steps}, CD: {cd_mean}, EMD: {emd_mean} (centered)\")\n",
    "    print(f\"Steps: {steps}, CD: {cd_mean_norm_sphere}, EMD: {emd_mean_norm_sphere} (normalized to unit sphere)\")\n",
    "    \n",
    "    return (cd_mean, emd_mean), (cd_mean_norm_sphere, emd_mean_norm_sphere)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_means(means, steps):\n",
    "    path = f'../metrics/{\"-\".join(categories)}/{scheduler}/{\"distilled\" if distilled else \"skip\"}/means/'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    filename = f\"{path}/means_{steps}.res\"\n",
    "    string = \"\"\n",
    "    for i, ((cd, emd), (cd_norm, emd_norm)) in enumerate(means):\n",
    "        string += f\"Steps: {steps:4d}\\n\"\n",
    "        string += f\"CD: {cd:.8f} | CD (norm): {cd_norm:.8f}\\n\"\n",
    "        string += f\"EMD: {emd:.8f} | EMD (norm): {emd_norm:.8f}\\n\"\n",
    "        string += \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    best_cd = min(means, key=lambda x: x[0][0])[0][0]\n",
    "    best_emd = min(means, key=lambda x: x[0][1])[0][1]\n",
    "    best_cd_norm = min(means, key=lambda x: x[1][0])[1][0]\n",
    "    best_emd_norm = min(means, key=lambda x: x[1][1])[1][1]\n",
    "    \n",
    "    string += f\"Best CD: {best_cd:.8f} | Best CD (norm): {best_cd_norm:.8f}\\n\"\n",
    "    string += f\"Best EMD: {best_emd:.8f} | Best EMD (norm): {best_emd_norm:.8f}\\n\"\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(string)\n",
    "        \n",
    "    print(f\"Saved means to {filename}\")\n",
    "\n",
    "for steps in steps_to_run:\n",
    "    means = [run_test(steps) for _ in range(1)]\n",
    "    # save_means(means, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35263",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
