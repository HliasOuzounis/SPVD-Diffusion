{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da82003-0d84-4548-add1-242747534f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/SPVD_Lightning/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e481a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils import data\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "synsetid_to_cate = {\n",
    "    '02691156': 'airplane', '02958343': 'car', '03001627': 'chair',\n",
    "   \n",
    "}\n",
    "cate_to_synsetid = {v: k for k, v in synsetid_to_cate.items()}\n",
    "\n",
    "\n",
    "class Uniform15KPC(Dataset):\n",
    "    def __init__(self, root_dir, subdirs, tr_sample_size=10000,\n",
    "                 te_sample_size=10000, split='train', scale=1.,\n",
    "                 normalize_per_shape=False, random_subsample=False,\n",
    "                 normalize_std_per_axis=False,\n",
    "                 all_points_mean=None, all_points_std=None,\n",
    "                 input_dim=3, load_renders=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.in_tr_sample_size = tr_sample_size\n",
    "        self.in_te_sample_size = te_sample_size\n",
    "        self.subdirs = subdirs\n",
    "        self.scale = scale\n",
    "        self.random_subsample = random_subsample\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.all_cate_mids = []\n",
    "        self.cate_idx_lst = []\n",
    "        self.all_points = []\n",
    "        self.renders = []\n",
    "        for cate_idx, subd in enumerate(self.subdirs):\n",
    "            # NOTE: [subd] here is synset id\n",
    "            sub_path = os.path.join(root_dir, \"pointclouds\", subd, self.split)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                print(\"Directory missing : %s\" % sub_path)\n",
    "                continue\n",
    "\n",
    "            all_mids = []\n",
    "            for x in os.listdir(sub_path):\n",
    "                if not x.endswith('.npy'):\n",
    "                    continue\n",
    "                all_mids.append(os.path.join(self.split, x[:-len('.npy')]))\n",
    "\n",
    "            # NOTE: [mid] contains the split: i.e. \"train/<mid>\" or \"val/<mid>\" or \"test/<mid>\"\n",
    "            for mid in tqdm(all_mids):\n",
    "                # obj_fname = os.path.join(sub_path, x)\n",
    "                obj_fname = os.path.join(root_dir, \"pointclouds\", subd, mid + \".npy\")\n",
    "                try:\n",
    "                    point_cloud = np.load(obj_fname)  # (15k, 3)\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                if load_renders:\n",
    "                    render_features = []\n",
    "                    for view in range(8):\n",
    "                        render_file = os.path.join(root_dir, 'embed_renders', subd, self.split, obj_fname.split('/')[-1].split('.')[0], f\"00{view}_patch_embs.pt\")\n",
    "                        if os.path.exists(render_file):\n",
    "                            render_features.append(torch.load(render_file, weights_only=True))\n",
    "                    render_features = torch.stack(render_features, dim=0)\n",
    "                    self.renders.append(render_features)\n",
    "\n",
    "                assert point_cloud.shape[0] == 15000\n",
    "                self.all_points.append(point_cloud[np.newaxis, ...])\n",
    "                self.cate_idx_lst.append(cate_idx)\n",
    "                self.all_cate_mids.append((subd, mid))\n",
    "\n",
    "        # Shuffle the index deterministically (based on the number of examples)\n",
    "        self.shuffle_idx = list(range(len(self.all_points)))\n",
    "        random.Random(38383).shuffle(self.shuffle_idx)\n",
    "        self.cate_idx_lst = [self.cate_idx_lst[i] for i in self.shuffle_idx]\n",
    "        self.all_points = [self.all_points[i] for i in self.shuffle_idx]\n",
    "        self.all_cate_mids = [self.all_cate_mids[i] for i in self.shuffle_idx]\n",
    "\n",
    "        # Normalization\n",
    "        self.all_points = np.concatenate(self.all_points)  # (N, 15000, 3)\n",
    "        self.normalize_per_shape = normalize_per_shape\n",
    "        self.normalize_std_per_axis = normalize_std_per_axis\n",
    "        if all_points_mean is not None and all_points_std is not None:  # using loaded dataset stats\n",
    "            self.all_points_mean = all_points_mean\n",
    "            self.all_points_std = all_points_std\n",
    "        elif self.normalize_per_shape:  # per shape normalization\n",
    "            B, N = self.all_points.shape[:2]\n",
    "            self.all_points_mean = self.all_points.mean(axis=1).reshape(B, 1, input_dim)\n",
    "            if normalize_std_per_axis:\n",
    "                self.all_points_std = self.all_points.reshape(B, N, -1).std(axis=1).reshape(B, 1, input_dim)\n",
    "            else:\n",
    "                self.all_points_std = self.all_points.reshape(B, -1).std(axis=1).reshape(B, 1, 1)\n",
    "        else:  # normalize across the dataset\n",
    "            self.all_points_mean = self.all_points.reshape(-1, input_dim).mean(axis=0).reshape(1, 1, input_dim)\n",
    "            if normalize_std_per_axis:\n",
    "                self.all_points_std = self.all_points.reshape(-1, input_dim).std(axis=0).reshape(1, 1, input_dim)\n",
    "            else:\n",
    "                self.all_points_std = self.all_points.reshape(-1).std(axis=0).reshape(1, 1, 1)\n",
    "\n",
    "        self.all_points = (self.all_points - self.all_points_mean) / self.all_points_std\n",
    "        self.train_points = self.all_points[:, :10000]\n",
    "        self.test_points = self.all_points[:, 10000:]\n",
    "\n",
    "        self.tr_sample_size = min(10000, tr_sample_size)\n",
    "        self.te_sample_size = min(5000, te_sample_size)\n",
    "        print(\"Total number of data:%d\" % len(self.train_points))\n",
    "        print(\"Min number of points: (train)%d (test)%d\"\n",
    "              % (self.tr_sample_size, self.te_sample_size))\n",
    "        assert self.scale == 1, \"Scale (!= 1) is deprecated\"\n",
    "\n",
    "    def get_pc_stats(self, idx):\n",
    "        if self.normalize_per_shape:\n",
    "            m = self.all_points_mean[idx].reshape(1, self.input_dim)\n",
    "            s = self.all_points_std[idx].reshape(1, -1)\n",
    "            return m, s\n",
    "\n",
    "        return self.all_points_mean.reshape(1, -1), self.all_points_std.reshape(1, -1)\n",
    "\n",
    "    def renormalize(self, mean, std):\n",
    "        self.all_points = self.all_points * self.all_points_std + self.all_points_mean\n",
    "        self.all_points_mean = mean\n",
    "        self.all_points_std = std\n",
    "        self.all_points = (self.all_points - self.all_points_mean) / self.all_points_std\n",
    "        self.train_points = self.all_points[:, :10000]\n",
    "        self.test_points = self.all_points[:, 10000:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tr_out = self.train_points[idx]\n",
    "        if self.random_subsample:\n",
    "            tr_idxs = np.random.choice(tr_out.shape[0], self.tr_sample_size)\n",
    "        else:\n",
    "            tr_idxs = np.arange(self.tr_sample_size)\n",
    "        tr_out = torch.from_numpy(tr_out[tr_idxs, :]).float()\n",
    "\n",
    "        te_out = self.test_points[idx]\n",
    "        if self.random_subsample:\n",
    "            te_idxs = np.random.choice(te_out.shape[0], self.te_sample_size)\n",
    "        else:\n",
    "            te_idxs = np.arange(self.te_sample_size)\n",
    "        te_out = torch.from_numpy(te_out[te_idxs, :]).float()\n",
    "\n",
    "        renders = self.renders[idx]\n",
    "        selected_view = np.random.randint(0, renders.shape[0])\n",
    "        render_features = renders[selected_view]\n",
    "\n",
    "        m, s = self.get_pc_stats(idx)\n",
    "        cate_idx = self.cate_idx_lst[idx]\n",
    "        sid, mid = self.all_cate_mids[idx]\n",
    "\n",
    "        return {\n",
    "            'idx': idx,\n",
    "            'train_points': tr_out,\n",
    "            'pc': te_out,\n",
    "            \"render-features\": render_features,\n",
    "            \"selected-view\": selected_view,\n",
    "            'mean': m, 'std': s, 'cate_idx': cate_idx,\n",
    "            'sid': sid, 'mid': mid\n",
    "        }\n",
    "\n",
    "class ShapeNet15kPointClouds(Uniform15KPC):\n",
    "    def __init__(self, root_dir=\"data/ShapeNetCore.v2.PC15k\",\n",
    "                 categories=['airplane'], tr_sample_size=10000, te_sample_size=2048,\n",
    "                 split='train', scale=1., normalize_per_shape=False,\n",
    "                 normalize_std_per_axis=False,\n",
    "                 random_subsample=False,\n",
    "                 all_points_mean=None, all_points_std=None, load_renders=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        assert self.split in ['train', 'test', 'val']\n",
    "        self.tr_sample_size = tr_sample_size\n",
    "        self.te_sample_size = te_sample_size\n",
    "        self.cates = categories\n",
    "        if 'all' in categories:\n",
    "            self.synset_ids = list(cate_to_synsetid.values())\n",
    "        else:\n",
    "            self.synset_ids = [cate_to_synsetid[c] for c in self.cates]\n",
    "\n",
    "        # assert 'v2' in root_dir, \"Only supporting v2 right now.\"\n",
    "        self.gravity_axis = 1\n",
    "        self.display_axis_order = [0, 2, 1]\n",
    "\n",
    "        super(ShapeNet15kPointClouds, self).__init__(\n",
    "            root_dir, self.synset_ids,\n",
    "            tr_sample_size=tr_sample_size,\n",
    "            te_sample_size=te_sample_size,\n",
    "            split=split, scale=scale,\n",
    "            normalize_per_shape=normalize_per_shape,\n",
    "            normalize_std_per_axis=normalize_std_per_axis,\n",
    "            random_subsample=random_subsample,\n",
    "            all_points_mean=all_points_mean, all_points_std=all_points_std,\n",
    "            input_dim=3, load_renders=load_renders)\n",
    "\n",
    "\n",
    "def init_np_seed(worker_id):\n",
    "    seed = torch.initial_seed()\n",
    "    np.random.seed(seed % 4294967296)\n",
    "    \n",
    "\n",
    "def get_datasets(args):\n",
    "    if args.dataset_type == 'shapenet15k':\n",
    "        tr_dataset = ShapeNet15kPointClouds(\n",
    "            categories=args.cates, split='train',\n",
    "            tr_sample_size=args.tr_max_sample_points,\n",
    "            te_sample_size=args.te_max_sample_points,\n",
    "            scale=args.dataset_scale, root_dir=args.data_dir,\n",
    "            normalize_per_shape=args.normalize_per_shape,\n",
    "            normalize_std_per_axis=args.normalize_std_per_axis,\n",
    "            random_subsample=True, load_renders=False)\n",
    "        te_dataset = ShapeNet15kPointClouds(\n",
    "            categories=args.cates, split='val',\n",
    "            tr_sample_size=args.tr_max_sample_points,\n",
    "            te_sample_size=args.te_max_sample_points,\n",
    "            scale=args.dataset_scale, root_dir=args.data_dir,\n",
    "            normalize_per_shape=args.normalize_per_shape,\n",
    "            normalize_std_per_axis=args.normalize_std_per_axis,\n",
    "            all_points_mean=tr_dataset.all_points_mean,\n",
    "            all_points_std=tr_dataset.all_points_std,\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Invalid dataset type:%s\" % args.dataset_type)\n",
    "\n",
    "    return te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b2a4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062da8031c554911ad61944d6054b929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data:2832\n",
      "Min number of points: (train)2048 (test)2048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbcc57a59e24be6a52d5750831271ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data:405\n",
      "Min number of points: (train)2048 (test)2048\n"
     ]
    }
   ],
   "source": [
    "def get_test_dataset(path, cates = ['chair']):\n",
    "    # using the same parameters as point flow\n",
    "    class Args: pass\n",
    "    args = Args()\n",
    "    args.data_dir = path\n",
    "    args.dataset_type = 'shapenet15k'\n",
    "    args.tr_max_sample_points = 2048\n",
    "    args.te_max_sample_points = 2048\n",
    "    args.dataset_scale = 1.\n",
    "    args.normalize_per_shape = False\n",
    "    args.normalize_std_per_axis = False\n",
    "    args.cates = cates\n",
    "\n",
    "    test_dataset = get_datasets(args)\n",
    "\n",
    "    return test_dataset\n",
    "\n",
    "categories = ['airplane']\n",
    "\n",
    "s = get_test_dataset('../data/ShapeNet', categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20845c22-fe21-4c71-b49b-48d79b2082ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ddpm_unet_cattn import SPVUnet\n",
    "import torch\n",
    "import lightning as L\n",
    "from models.g_spvd import GSPVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5649e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "# steps_to_run = [1000, 500, 250, 125, 63, 32, 16, 8, 4, 2]\n",
    "steps_to_run = [1000]\n",
    "on_all = True\n",
    "distilled = False\n",
    "scheduler = 'ddpm'\n",
    "\n",
    "# categories = ['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249073ab-7415-4203-ade8-42a077ded01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataloaders.shapenet.shapenet_loader import ShapeNet\n",
    "\n",
    "path = \"../data/ShapeNet\"\n",
    "\n",
    "# test_dataset = ShapeNet(path, \"test\", 2048, categories, load_renders=True, total=800 if on_all else 5)\n",
    "test_loader = DataLoader(s, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c35c796-1d0f-44df-876c-22d74ee96ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hyperparams import load_hyperparams\n",
    "\n",
    "hparams_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/hparams.yaml'\n",
    "\n",
    "hparams = load_hyperparams(hparams_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab32803-eef3-4c2c-82e1-52fd6af63063",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'voxel_size' : hparams['voxel_size'],\n",
    "    'nfs' : hparams['nfs'], \n",
    "    'attn_chans' : hparams['attn_chans'], \n",
    "    'attn_start' : hparams['attn_start'], \n",
    "    'cross_attn_chans' : hparams['cross_attn_chans'], \n",
    "    'cross_attn_start' : hparams['cross_attn_start'], \n",
    "    'cross_attn_cond_dim' : hparams['cross_attn_cond_dim'],\n",
    "}\n",
    "\n",
    "model = SPVUnet(**model_args)\n",
    "model = GSPVD(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9946f0a2-d343-4d56-847f-c55de5273595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7a8036-ef5c-4200-bb05-74ea77a1e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_schedulers.ddpm_scheduler import DDPMSparseScheduler\n",
    "from my_schedulers.ddim_scheduler import DDIMSparseScheduler\n",
    "from utils.helper_functions import process_ckpt\n",
    "from schedulers.factory import create_sparse_scheduler\n",
    "\n",
    "\n",
    "def get_sched(steps, dist, scheduler):\n",
    "    \n",
    "    return create_sparse_scheduler(\n",
    "        scheduler_strategy=scheduler.upper(),\n",
    "        beta_min=hparams['beta_min'], \n",
    "        beta_max=hparams['beta_max'], \n",
    "        n_steps=steps, \n",
    "        scheduling_method='linear' if hparams['mode'] == 'linear' else 'warmup',\n",
    "    )\n",
    "\n",
    "def get_ckpt(steps, dist, scheduler):\n",
    "    if dist:\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/new/{steps}-steps.ckpt'\n",
    "    elif scheduler == 'ddim':\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "    else:\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "    ckpt = process_ckpt(ckpt)\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30779293-ab3f-40fe-a825-70e470751932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from metrics.chamfer_dist import ChamferDistanceL2\n",
    "from metrics.PyTorchEMD.emd import earth_mover_distance as EMD\n",
    "from utils.helper_functions import normalize_to_unit_sphere, standardize, normalize_to_unit_cube\n",
    "\n",
    "def run_test(steps):\n",
    "    CD = ChamferDistanceL2()\n",
    "    \n",
    "    sched = get_sched(steps, distilled, scheduler)\n",
    "\n",
    "    ckpt = get_ckpt(steps, distilled, scheduler)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "    cd_mean = 0\n",
    "    emd_mean = 0\n",
    "    cd_mean_norm_sphere = 0\n",
    "    emd_mean_norm_sphere = 0\n",
    "    n = 0\n",
    "    \n",
    "    # mean = torch.tensor(test_dataset.mean).cuda()\n",
    "    # std = torch.tensor(test_dataset.std).cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for datapoint in tqdm(test_loader):\n",
    "            # print(list(datapoint.keys()))\n",
    "            ref_pc = datapoint['pc'].cuda()\n",
    "            features = datapoint['render-features'].cuda()\n",
    "\n",
    "            B, N, C = ref_pc.shape\n",
    "            gen_pc = sched.sample(model=model, bs=B, n_points=N, nf=C, cond_emb=features, mode='conditional').cuda()\n",
    "            \n",
    "            # print(ref_pc.device, gen_pc.device)\n",
    "            # ref_pc = ref_pc * std + mean\n",
    "            # gen_pc = gen_pc * std + mean\n",
    "            \n",
    "            # ref_pc: (B, N, F)\n",
    "            ref_pc_zero = ref_pc - ref_pc.mean(dim=1, keepdim=True)\n",
    "            gen_pc_zero = gen_pc - gen_pc.mean(dim=1, keepdim=True)\n",
    "            \n",
    "            # print(ref_pc_zero.max(), ref_pc_zero.min())\n",
    "\n",
    "            # ref_pc_zero.mean: (B, 1, F)\n",
    "            # ref_pc_zero.std: (B, 1, 1) \n",
    "            # ref_pc_zero = ref_pc_zero / ref_pc_zero.std(dim=(1, 2), keepdim=True)\n",
    "            # gen_pc_zero = gen_pc_zero / gen_pc_zero.std(dim=(1, 2), keepdim=True)\n",
    "            \n",
    "\n",
    "            cd_mean += CD(ref_pc_zero, gen_pc_zero).item() * B\n",
    "            \n",
    "            # emd_mean += EMD(ref_pc, gen_pc, transpose=False).sum().item()\n",
    "            \n",
    "            ref_pc_norm = normalize_to_unit_sphere(ref_pc)\n",
    "            gen_pc_norm = normalize_to_unit_sphere(gen_pc)\n",
    "\n",
    "            cd_mean_norm_sphere += CD(ref_pc_norm, gen_pc_norm).item() * B\n",
    "            # emd_mean_norm_sphere += EMD(ref_pc_norm, gen_pc_norm, transpose=False).sum().item()\n",
    "            \n",
    "            n += B\n",
    "            print(cd_mean / n)\n",
    "        \n",
    "    cd_mean /= n\n",
    "    emd_mean /= n\n",
    "    \n",
    "    cd_mean_norm_sphere /= n\n",
    "    emd_mean_norm_sphere /= n\n",
    "    \n",
    "    print(f\"Steps: {steps}, CD: {cd_mean}, EMD: {emd_mean} (centered)\")\n",
    "    print(f\"Steps: {steps}, CD: {cd_mean_norm_sphere}, EMD: {emd_mean_norm_sphere} (normalized to unit sphere)\")\n",
    "    \n",
    "    return (cd_mean, emd_mean), (cd_mean_norm_sphere, emd_mean_norm_sphere)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb0c9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2639f63603b4eecbc65953469b818ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a569a536f8e2426ab4142faf16191222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sampling:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045626357197761536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c87cbc2df54eb2812a6580dafcc7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sampling:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved means to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m steps \u001b[38;5;129;01min\u001b[39;00m steps_to_run:\n\u001b[0;32m---> 29\u001b[0m     means \u001b[38;5;241m=\u001b[39m [run_test(steps) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# save_means(means, steps)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved means to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m steps \u001b[38;5;129;01min\u001b[39;00m steps_to_run:\n\u001b[0;32m---> 29\u001b[0m     means \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# save_means(means, steps)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(steps)\u001b[0m\n\u001b[1;32m     28\u001b[0m features \u001b[38;5;241m=\u001b[39m datapoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender-features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     30\u001b[0m B, N, C \u001b[38;5;241m=\u001b[39m ref_pc\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 31\u001b[0m gen_pc \u001b[38;5;241m=\u001b[39m \u001b[43msched\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconditional\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(ref_pc.device, gen_pc.device)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# ref_pc = ref_pc * std + mean\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# gen_pc = gen_pc * std + mean\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# ref_pc: (B, N, F)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m ref_pc_zero \u001b[38;5;241m=\u001b[39m ref_pc \u001b[38;5;241m-\u001b[39m ref_pc\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/schedulers/schedulers.py:107\u001b[0m, in \u001b[0;36mSparseScheduler.sample\u001b[0;34m(self, model, bs, n_points, nf, cond_emb, uncond_emb, guidance_scale, mode, save_process)\u001b[0m\n\u001b[1;32m    104\u001b[0m preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pc(x_t, shape)] \u001b[38;5;28;01mif\u001b[39;00m save_process \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39msteps, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)):\n\u001b[0;32m--> 107\u001b[0m     x_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43muncond_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_process:\n\u001b[1;32m    120\u001b[0m         preds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pc(x_t, shape))\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/schedulers/schedulers.py:147\u001b[0m, in \u001b[0;36mSparseScheduler.sample_step\u001b[0;34m(self, model, x_t, t, i, cond_emb, uncond_emb, shape, device, guidance_scale, mode)\u001b[0m\n\u001b[1;32m    144\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m model((x_t, t_batch, uncond_emb))\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconditional\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Fully conditional generation\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_emb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguided\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# Classifier-free guidance\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# Conditional prediction\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     noise_pred_cond \u001b[38;5;241m=\u001b[39m model((x_t, t_batch, cond_emb))\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/models/g_spvd.py:16\u001b[0m, in \u001b[0;36mGSPVD.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/models/ddpm_unet_cattn.py:204\u001b[0m, in \u001b[0;36mSPVUnet.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    201\u001b[0m     x \u001b[38;5;241m=\u001b[39m mb(x, emb)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mups:\n\u001b[0;32m--> 204\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m z1 \u001b[38;5;241m=\u001b[39m voxel_to_point(x, z)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_point_branch:\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/models/ddpm_unet_cattn.py:113\u001b[0m, in \u001b[0;36mUpBlock.forward\u001b[0;34m(self, x, t, ups, cond)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, ups, cond\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m resnet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnets: x \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchsparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x)\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/models/ddpm_unet_cattn.py:84\u001b[0m, in \u001b[0;36mEmbResBlock.forward\u001b[0;34m(self, x_in, t, cond)\u001b[0m\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(x) \u001b[38;5;66;03m# Residual connection inside the attention module\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m---> 84\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Residual connection inside the cross attention module\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SPVD_Lightning/src/models/modules/transformer.py:212\u001b[0m, in \u001b[0;36mSparseCrossAttention.forward\u001b[0;34m(self, x, cond_emb)\u001b[0m\n\u001b[1;32m    209\u001b[0m     cond_emb \u001b[38;5;241m=\u001b[39m cond_emb\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (B, 1, dim)\u001b[39;00m\n\u001b[1;32m    211\u001b[0m x_dense \u001b[38;5;241m=\u001b[39m x_dense \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x_dense), cond_emb)\n\u001b[0;32m--> 212\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mF\u001b[49m \u001b[38;5;241m=\u001b[39m x_dense[mask]\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/envs/12.4/lib/python3.10/site-packages/torchsparse/tensor.py:58\u001b[0m, in \u001b[0;36mSparseTensor.F\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mF\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeats\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;129m@F\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mF\u001b[39m(\u001b[38;5;28mself\u001b[39m, feats: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeats \u001b[38;5;241m=\u001b[39m feats\n\u001b[1;32m     62\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mC\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def save_means(means, steps):\n",
    "    path = f'../metrics/{\"-\".join(categories)}/{scheduler}/{\"distilled\" if distilled else \"skip\"}/means/'\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    filename = f\"{path}/means_{steps}.res\"\n",
    "    string = \"\"\n",
    "    for i, ((cd, emd), (cd_norm, emd_norm)) in enumerate(means):\n",
    "        string += f\"Steps: {steps:4d}\\n\"\n",
    "        string += f\"CD: {cd:.8f} | CD (norm): {cd_norm:.8f}\\n\"\n",
    "        string += f\"EMD: {emd:.8f} | EMD (norm): {emd_norm:.8f}\\n\"\n",
    "        string += \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    best_cd = min(means, key=lambda x: x[0][0])[0][0]\n",
    "    best_emd = min(means, key=lambda x: x[0][1])[0][1]\n",
    "    best_cd_norm = min(means, key=lambda x: x[1][0])[1][0]\n",
    "    best_emd_norm = min(means, key=lambda x: x[1][1])[1][1]\n",
    "    \n",
    "    string += f\"Best CD: {best_cd:.8f} | Best CD (norm): {best_cd_norm:.8f}\\n\"\n",
    "    string += f\"Best EMD: {best_emd:.8f} | Best EMD (norm): {best_emd_norm:.8f}\\n\"\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(string)\n",
    "        \n",
    "    print(f\"Saved means to {filename}\")\n",
    "\n",
    "for steps in steps_to_run:\n",
    "    means = [run_test(steps) for _ in range(1)]\n",
    "    # save_means(means, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35263",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
