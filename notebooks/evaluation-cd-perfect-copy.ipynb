{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../src\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the notebook's directory using os.getcwd() or pathlib\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Calculate the main directory (notebooks are in a \"notebooks\" folder)\n",
    "main_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the main directory to sys.path\n",
    "if main_dir not in sys.path:\n",
    "    sys.path.insert(0, main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloaders.giannis_shapenet import ShapeNet15kPointClouds, ShapeNet15kPointCloudsViTEmbs\n",
    "from dataloaders.transforms import DDPMNoisify, TorchSparseVoxelize\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "\n",
    "from models.ddpm_unet_cattn import SPVUnet\n",
    "from models.g_spvd import GSPVD\n",
    "\n",
    "from metrics.chamfer_dist import ChamferDistanceL2\n",
    "from metrics.PyTorchEMD.emd import earth_mover_distance as EMD\n",
    "\n",
    "from schedulers.factory import create_sparse_scheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = \"../data/ShapeNet/pointclouds\"\n",
    "embedding_path = \"../data/ShapeNet/embed_renders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['car']\n",
    "# categories = ['airplane']\n",
    "# categories = ['chair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the validation dataset\n",
    "dataset = ShapeNet15kPointCloudsViTEmbs(dataset_path, embedding_path,\n",
    "                                        split='val', categories=categories, tr_sample_size=2048, random_subsample=False)\n",
    "dataloader = DataLoader(dataset, 32, shuffle=False, drop_last=False, collate_fn = sparse_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_functions import process_ckpt\n",
    "import torch\n",
    "\n",
    "# 2. Load the model\n",
    "spv_unet = SPVUnet(\n",
    "        voxel_size=0.1,\n",
    "        nfs=[32,64,128,256],\n",
    "        attn_chans=8,\n",
    "        attn_start=3,\n",
    "        cross_attn_chans=8,\n",
    "        cross_attn_start=2,\n",
    "        cross_attn_cond_dim=768\n",
    "    )\n",
    "\n",
    "model = GSPVD(\n",
    "        model=spv_unet\n",
    "    )\n",
    "\n",
    "# ckpt_path = ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "# ckpt_path = '/home/ubuntu/SPVD_Lightning/checkpoints/ShapeNet/GSPVD/airplane/ddpm/1000-steps.ckpt'\n",
    "# ckpt_path = '/home/ubuntu/SPVD_Lightning/checkpoints/ImageGuidedSPVD/version_3/checkpoints/epoch=4999-step=385000.ckpt' # Car\n",
    "ckpt_path = '/home/ubuntu/SPVD_Lightning/checkpoints/distillation/GSPVD/car/intemediate/500-steps/500-steps-epoch=249.ckpt' # Car\n",
    "# ckpt_path = '/home/ubuntu/SPVD_Lightning/checkpoints/ImageGuidedSPVD/version_0/checkpoints/epoch=2499-step=362500.ckpt' # Chair\n",
    "\n",
    "ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "ckpt = process_ckpt(ckpt)\n",
    "model.load_state_dict(ckpt)\n",
    "# model.load_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = create_sparse_scheduler() # Chair, Car\n",
    "# scheduler = create_sparse_scheduler(beta_min=1e-5, beta_max=0.008, scheduling_method='warmup') #Airplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from metrics.rgb2point import EMDLoss, chamfer_distance\n",
    "from metrics.chamfer_dist import ChamferDistanceL2\n",
    "from metrics.PyTorchEMD.emd import earth_mover_distance as EMD\n",
    "\n",
    "emd_loss_fn = EMDLoss()\n",
    "\n",
    "cd_loss = 0\n",
    "emd_loss = 0\n",
    "cd_1 = 0\n",
    "emd_1 = 0\n",
    "n_samples = 0\n",
    "\n",
    "CD = ChamferDistanceL2()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        gt_pc = batch['train_points'].cuda()\n",
    "        cond_emb = batch['vit_emb'].cuda()\n",
    "        B = gt_pc.shape[0]\n",
    "        gen_pc = scheduler.sample(model, B, cond_emb = cond_emb, mode='conditional').cuda()\n",
    "        # Center Point Clouds\n",
    "        gt_pc = gt_pc - gt_pc.mean(dim=1, keepdim=True)\n",
    "        #gt_pc = gt_pc / gt_pc.std(dim=1, keepdim=True)\n",
    "        # Point Clouds should have the max distance from the origin equal to 0.64\n",
    "        r = (gt_pc * gt_pc).sum(dim=-1).sqrt().max(dim=1, keepdim=True)[0]\n",
    "        #print(f'Max radius: {r.shape}')\n",
    "        #print(gt_pc.shape)\n",
    "        gt_pc = gt_pc / r.unsqueeze(-1) * 0.64\n",
    "        # Shuffle Points in each point cloud of the batch\n",
    "        gt_pc = gt_pc[:, torch.randperm(gt_pc.shape[1])]\n",
    "        gt_pc = gt_pc[:, :1024] # Take only 1024 points from each point cloud\n",
    "        gen_pc = gen_pc - gen_pc.mean(dim=1, keepdim=True)\n",
    "        #gen_pc = gen_pc / gen_pc.std(dim=1, keepdim=True)\n",
    "        # Point Clouds should have the max distance from the origin equal to 0.64\n",
    "        r = (gen_pc * gen_pc).sum(dim=-1).sqrt().max(dim=1, keepdim=True)[0]\n",
    "        # print(f'Max radius: {r}')\n",
    "        gen_pc = gen_pc / r.unsqueeze(-1) * 0.64\n",
    "        # Shuffle Points in each point cloud of the batch\n",
    "        gen_pc = gen_pc[:, torch.randperm(gen_pc.shape[1])]\n",
    "        gen_pc = gen_pc[:, :1024]\n",
    "\n",
    "        cd_1 += CD(gt_pc, gen_pc).item() * B\n",
    "        emd_1 += EMD(gt_pc, gen_pc, transpose=False).sum().item()\n",
    "\n",
    "        for gpc, gtpc in zip(gen_pc, gt_pc):\n",
    "            cd = chamfer_distance(gpc.cpu().numpy(), gtpc.cpu().numpy(), metric=\"l2\", direction=\"x_to_y\")\n",
    "            cd_loss += cd\n",
    "            emd_loss += emd_loss_fn(gpc.unsqueeze(0), gtpc.unsqueeze(0)).item()\n",
    "            n_samples += 1\n",
    "\n",
    "        # # Reconstruction loss\n",
    "        # cd_loss += CD(gen_pc, gt_pc).item() * B # Returns mean batch loss\n",
    "        # emd_loss += EMD(gen_pc, gt_pc, transpose=False).sum().item() # Returns per element loss\n",
    "        # n_samples += B\n",
    "\n",
    "        print(f'So far - Chamfer Distance: {cd_loss / n_samples} | EMD: {emd_loss / n_samples}')\n",
    "        print(f\"CD: {cd_1 / n_samples}, EMD: {emd_1 / n_samples}\")\n",
    "\n",
    "\n",
    "cd_loss = cd_loss / n_samples\n",
    "emd_loss = emd_loss / n_samples\n",
    "\n",
    "print(f'Chamfer Distance: {cd_loss} | EMD: {emd_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
