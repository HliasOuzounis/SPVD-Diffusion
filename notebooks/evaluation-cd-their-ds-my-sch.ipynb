{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../src\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ddpm_unet_cattn import SPVUnet\n",
    "import torch\n",
    "import lightning as L\n",
    "from models.g_spvd import GSPVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "# steps_to_run = [1000, 500, 250, 125, 63, 32, 16, 8, 4, 2]\n",
    "steps_to_run = [1000]\n",
    "on_all = True\n",
    "distilled = False\n",
    "scheduler = 'ddim'\n",
    "\n",
    "categories = ['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hyperparams import load_hyperparams\n",
    "\n",
    "hparams_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/hparams.yaml'\n",
    "\n",
    "hparams = load_hyperparams(hparams_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.giannis_shapenet import ShapeNet15kPointCloudsViTEmbs, ShapeNet15kPointClouds\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_path = \"../data/ShapeNet/pointclouds\"\n",
    "emb_path = \"../data/ShapeNet/embed_renders\"\n",
    "\n",
    "dataset = ShapeNet15kPointCloudsViTEmbs(\n",
    "    dataset_path, \n",
    "    emb_path,\n",
    "    split='test',\n",
    "    categories=categories, \n",
    "    tr_sample_size=2048, \n",
    "    random_subsample=False,\n",
    ")\n",
    "dataloader = DataLoader(dataset, 32, shuffle=False, drop_last=False, collate_fn = sparse_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'voxel_size' : hparams['voxel_size'],\n",
    "    'nfs' : hparams['nfs'], \n",
    "    'attn_chans' : hparams['attn_chans'], \n",
    "    'attn_start' : hparams['attn_start'], \n",
    "    'cross_attn_chans' : hparams['cross_attn_chans'], \n",
    "    'cross_attn_start' : hparams['cross_attn_start'], \n",
    "    'cross_attn_cond_dim' : hparams['cross_attn_cond_dim'],\n",
    "}\n",
    "\n",
    "model = SPVUnet(**model_args)\n",
    "model = GSPVD(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_schedulers.ddpm_scheduler import DDPMSparseScheduler\n",
    "from my_schedulers.ddim_scheduler import DDIMSparseScheduler\n",
    "from utils.helper_functions import process_ckpt\n",
    "from schedulers.factory import create_sparse_scheduler\n",
    "\n",
    "\n",
    "def get_sched(steps, dist, scheduler):\n",
    "    if scheduler == 'ddim':\n",
    "        sched = DDIMSparseScheduler(\n",
    "            beta_min=hparams['beta_min'], \n",
    "            beta_max=hparams['beta_max'], \n",
    "            steps=steps, \n",
    "            init_steps=hparams['n_steps'],\n",
    "            mode=hparams['mode'],\n",
    "        )\n",
    "    elif dist:\n",
    "        sched = DDPMSparseScheduler(\n",
    "            beta_min=hparams['beta_min'], \n",
    "            beta_max=hparams['beta_max'], \n",
    "            steps=steps, \n",
    "            init_steps=hparams['n_steps'],\n",
    "            mode=hparams['mode'],\n",
    "        )\n",
    "    else:\n",
    "        sched = DDPMSparseScheduler(\n",
    "            beta_min=hparams['beta_min'], \n",
    "            beta_max=hparams['beta_max'], \n",
    "            steps=steps,\n",
    "            init_steps=steps,\n",
    "            mode=hparams['mode'],\n",
    "        )\n",
    "    return sched\n",
    "\n",
    "def get_ckpt(steps, dist, scheduler):\n",
    "    if dist:\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/new/{steps}-steps.ckpt'\n",
    "    elif scheduler == 'ddim':\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "    else:\n",
    "        ckpt_path = f'../checkpoints/distillation/GSPVD/{\"-\".join(categories)}/1000-steps.ckpt'\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "    ckpt = process_ckpt(ckpt)\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from metrics.chamfer_dist import ChamferDistanceL2\n",
    "from metrics.PyTorchEMD.emd import earth_mover_distance as EMD\n",
    "from utils.helper_functions import normalize_to_unit_sphere, standardize, normalize_to_unit_cube\n",
    "from schedulers.factory import create_sparse_scheduler\n",
    "\n",
    "from metrics.rgb2point import chamfer_distance, EMDLoss\n",
    "\n",
    "emd_loss = EMDLoss()\n",
    "\n",
    "def run_test(steps):\n",
    "    CD = ChamferDistanceL2()\n",
    "    \n",
    "    sched = get_sched(steps, distilled, scheduler)\n",
    "    # sched = create_sparse_scheduler() # Chair, Car\n",
    "\n",
    "    ckpt = get_ckpt(steps, distilled, scheduler)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "    cd_mean = 0\n",
    "    emd_mean = 0\n",
    "    n = 0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for datapoint in tqdm(dataloader):\n",
    "            ref_pc = datapoint['train_points'].cuda()\n",
    "            features = datapoint['vit_emb'].cuda()\n",
    "\n",
    "            B, N, C = ref_pc.shape\n",
    "            gen_pc = sched.sample(model, B, N, reference=features)\n",
    "            # gen_pc = sched.sample(model=model, bs=B, n_points=N, nf=C, cond_emb=features, mode='conditional').cuda()\n",
    "            \n",
    "            ref_pc = ref_pc - ref_pc.mean(dim=1, keepdim=True)\n",
    "            # Point Clouds should have the max distance from the origin equal to 0.64\n",
    "            r = (ref_pc * ref_pc).sum(dim=-1).sqrt().max(dim=1, keepdim=True)[0]\n",
    "            #print(f'Max radius: {r.shape}')\n",
    "            #print(ref_pc.shape)\n",
    "            ref_pc = ref_pc / r.unsqueeze(-1) * 0.64\n",
    "            # Shuffle Points in each point cloud of the batch\n",
    "            ref_pc = ref_pc[:, torch.randperm(ref_pc.shape[1])]\n",
    "            ref_pc = ref_pc[:, :1024] # Take only 1024 points from each point cloud\n",
    "\n",
    "            gen_pc = gen_pc - gen_pc.mean(dim=1, keepdim=True)\n",
    "            # Point Clouds should have the max distance from the origin equal to 0.64\n",
    "            r = (gen_pc * gen_pc).sum(dim=-1).sqrt().max(dim=1, keepdim=True)[0]\n",
    "            # print(f'Max radius: {r}')\n",
    "            gen_pc = gen_pc / r.unsqueeze(-1) * 0.64\n",
    "            # Shuffle Points in each point cloud of the batch\n",
    "            gen_pc = gen_pc[:, torch.randperm(gen_pc.shape[1])]\n",
    "            gen_pc = gen_pc[:, :1024]\n",
    "\n",
    "            for g, r in tqdm(zip(ref_pc, gen_pc), leave=False):\n",
    "                g = g.detach().cpu()\n",
    "                r = r.detach().cpu()\n",
    "                cd_mean += chamfer_distance(g, r, direction='bi') / 2\n",
    "            \n",
    "            emd_mean += emd_loss(ref_pc, gen_pc)\n",
    "            \n",
    "            n += B\n",
    "            print(f\"CD: {cd_mean / n}\")\n",
    "        \n",
    "    cd_mean /= n\n",
    "    emd_mean /= n\n",
    "       \n",
    "    print(f\"Steps: {steps}, CD: {cd_mean}\")\n",
    "    \n",
    "    return (cd_mean, emd_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for steps in steps_to_run:\n",
    "    means = [run_test(steps) for _ in range(1)]\n",
    "    # save_means(means, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
